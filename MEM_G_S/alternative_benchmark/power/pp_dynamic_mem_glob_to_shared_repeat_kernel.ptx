//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Thu Mar 13 12:31:35 2014 (1394735495)
// Cuda compilation tools, release 6.0, V6.0.1
//

.version 4.0
.target sm_35
.address_size 64

// _Z17reverse_in_chunksPKfPfii$__cuda_local_var_34559_33_non_const_sharedA has been demoted

.weak .func  (.param .b32 func_retval0) cudaMalloc(
	.param .b64 cudaMalloc_param_0,
	.param .b64 cudaMalloc_param_1
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

.weak .func  (.param .b32 func_retval0) cudaFuncGetAttributes(
	.param .b64 cudaFuncGetAttributes_param_0,
	.param .b64 cudaFuncGetAttributes_param_1
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

.visible .entry _Z17reverse_in_chunksPKfPfii(
	.param .u64 _Z17reverse_in_chunksPKfPfii_param_0,
	.param .u64 _Z17reverse_in_chunksPKfPfii_param_1,
	.param .u32 _Z17reverse_in_chunksPKfPfii_param_2,
	.param .u32 _Z17reverse_in_chunksPKfPfii_param_3
)
{
	.reg .pred 	%p<6>;
	.reg .s32 	%r<35>;
	.reg .f32 	%f<3>;
	.reg .s64 	%rd<31>;
	// demoted variable
	.shared .align 4 .b8 _Z17reverse_in_chunksPKfPfii$__cuda_local_var_34559_33_non_const_sharedA[45056];

	ld.param.u64 	%rd17, [_Z17reverse_in_chunksPKfPfii_param_0];
	ld.param.u64 	%rd18, [_Z17reverse_in_chunksPKfPfii_param_1];
	ld.param.u32 	%r17, [_Z17reverse_in_chunksPKfPfii_param_2];
	ld.param.u32 	%r18, [_Z17reverse_in_chunksPKfPfii_param_3];
	cvta.to.global.u64 	%rd19, %rd18;
	cvta.to.global.u64 	%rd1, %rd17;
	shl.b32 	%r1, %r17, 10;
	mov.u32 	%r19, %ctaid.x;
	mul.lo.s32 	%r2, %r1, %r19;
	mul.wide.s32 	%rd20, %r1, 780903145;
	shr.u64 	%rd21, %rd20, 63;
	cvt.u32.u64	%r20, %rd21;
	shr.s64 	%rd22, %rd20, 43;
	cvt.u32.u64	%r21, %rd22;
	add.s32 	%r3, %r21, %r20;
	mul.lo.s32 	%r22, %r19, %r17;
	shl.b32 	%r23, %r22, 10;
	mov.u32 	%r24, %tid.x;
	add.s32 	%r4, %r24, %r23;
	mul.wide.s32 	%rd23, %r24, 4;
	mov.u64 	%rd24, _Z17reverse_in_chunksPKfPfii$__cuda_local_var_34559_33_non_const_sharedA;
	add.s64 	%rd4, %rd24, %rd23;
	add.s64 	%rd3, %rd19, -45056;
	sub.s32 	%r25, %r18, %r24;
	sub.s32 	%r5, %r25, %r23;
	mov.u32 	%r30, 0;

BB2_1:
	setp.lt.s32	%p1, %r1, 11264;
	@%p1 bra 	BB2_8;

	mov.u32 	%r31, 0;

BB2_3:
	mad.lo.s32 	%r27, %r31, -11264, %r5;
	mul.wide.s32 	%rd25, %r27, 4;
	add.s64 	%rd30, %rd3, %rd25;
	mul.lo.s32 	%r28, %r31, 11264;
	add.s32 	%r29, %r4, %r28;
	mul.wide.s32 	%rd26, %r29, 4;
	add.s64 	%rd28, %rd1, %rd26;
	add.s32 	%r33, %r28, %r2;
	add.s32 	%r9, %r33, 11264;
	mov.u64 	%rd27, %rd4;
	mov.u32 	%r34, %r33;

BB2_4:
	ld.global.f32 	%f1, [%rd28];
	st.shared.f32 	[%rd27], %f1;
	add.s64 	%rd28, %rd28, 4096;
	add.s64 	%rd27, %rd27, 4096;
	add.s32 	%r34, %r34, 1024;
	setp.lt.s32	%p2, %r34, %r9;
	@%p2 bra 	BB2_4;

	mov.u64 	%rd29, %rd4;
	bar.sync 	0;

BB2_6:
	ld.shared.f32 	%f2, [%rd29];
	st.global.f32 	[%rd30], %f2;
	add.s64 	%rd30, %rd30, -4096;
	add.s64 	%rd29, %rd29, 4096;
	add.s32 	%r33, %r33, 1024;
	setp.lt.s32	%p3, %r33, %r9;
	@%p3 bra 	BB2_6;

	add.s32 	%r31, %r31, 1;
	setp.lt.s32	%p4, %r31, %r3;
	@%p4 bra 	BB2_3;

BB2_8:
	add.s32 	%r30, %r30, 1;
	setp.lt.s32	%p5, %r30, 400;
	@%p5 bra 	BB2_1;

	ret;
}


